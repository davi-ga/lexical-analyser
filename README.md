# Analisador L√©xico - Compiladores

Primeira parte do trabalho de Compiladores do curso de Ci√™ncia da Computa√ß√£o do IFG-An√°polis.

## üìù Descri√ß√£o

Este projeto implementa um **analisador l√©xico** para identificar e classificar tokens de uma linguagem de programa√ß√£o simplificada, com foco especial na **detec√ß√£o de erros l√©xicos**. O analisador processa arquivos de c√≥digo fonte e categoriza cada token encontrado, identificando quando h√° palavras-chave escritas incorretamente ou outras inconsist√™ncias lexicais.

## üéØ Objetivos

- **Identificar erros l√©xicos** em c√≥digo fonte
- **Classificar tokens** em categorias (palavras-chave, vari√°veis, identificadores, etc.)
- **Detectar similaridades** entre tokens incorretos e palavras-chave v√°lidas
- **Processar m√∫ltiplos arquivos** automaticamente

## üîß Funcionalidades

### Classifica√ß√£o de Tokens
O analisador identifica os seguintes tipos de tokens:

- **KEYWORD**: Palavras-chave da linguagem (`principal`, `inteiro`, `escreva`, `leia`, etc.)
- **VARIABLE**: Vari√°veis (devem come√ßar com `!`)
- **FUNC_NAME**: Nomes de fun√ß√µes (devem come√ßar com `__`)
- **INTEGER**: N√∫meros inteiros
- **IDENTIFIER/OTHER**: Outros identificadores v√°lidos
- **LEFT_PAREN/RIGHT_PAREN**: Par√™nteses `(` e `)`
- **LEFT_BRACE/RIGHT_BRACE**: Chaves `{` e `}`
- **SEMICOLON**: Ponto e v√≠rgula `;`
- **LEXICAL ERROR**: Tokens com erros l√©xicos

### Detec√ß√£o de Erros L√©xicos
O sistema utiliza o **algoritmo de dist√¢ncia de Levenshtein** para detectar:

- Palavras-chave escritas incorretamente (ex: `pincipal` ‚Üí `principal`)
- Varia√ß√µes com caracteres faltando ou extras
- Prefixos de palavras-chave v√°lidas

### Linguagem Suportada

#### Palavras-chave:
- `principal` - fun√ß√£o principal
- `inteiro` - tipo de dados inteiro
- `retorno` - comando de retorno
- `escreva` - comando de sa√≠da
- `leia` - comando de entrada
- `funcao` - declara√ß√£o de fun√ß√£o
- `se` - condicional if
- `senao` - condicional else
- `para` - la√ßo for

#### Regras de Sintaxe:
- **Vari√°veis**: devem come√ßar com `!` (ex: `!a`, `!numero`)
- **Fun√ß√µes**: devem come√ßar com `__` (ex: `__soma`)
- **Strings**: delimitadas por aspas duplas

## üìÅ Estrutura do Projeto

```
compiler/
‚îú‚îÄ‚îÄ main.c                 # C√≥digo principal do analisador
‚îú‚îÄ‚îÄ main                   # Execut√°vel compilado
‚îú‚îÄ‚îÄ ASCII.TXT             # Arquivo de refer√™ncia ASCII
‚îú‚îÄ‚îÄ data/                 # Arquivos de teste (.txt)
‚îÇ   ‚îú‚îÄ‚îÄ exemplo_1.txt
‚îÇ   ‚îú‚îÄ‚îÄ exemplo_2.txt
‚îÇ   ‚îú‚îÄ‚îÄ exemplo_3.txt
‚îÇ   ‚îú‚îÄ‚îÄ exemplo_4.txt
‚îÇ   ‚îú‚îÄ‚îÄ Erro_exemplo_5.txt
‚îÇ   ‚îú‚îÄ‚îÄ Erro_exemplo_6.txt
‚îÇ   ‚îú‚îÄ‚îÄ Erro_Exemplo_7.txt
‚îÇ   ‚îú‚îÄ‚îÄ Erro_Exemplo_8.txt
‚îÇ   ‚îî‚îÄ‚îÄ Erro_Exemplo_9.txt
‚îî‚îÄ‚îÄ datartf/              # Arquivos de teste (.rtf)
    ‚îî‚îÄ‚îÄ [mesmos arquivos em formato RTF]
```

## üöÄ Como Executar

### Pr√©-requisitos
- Compilador GCC
- Sistema Linux/Unix

### Compila√ß√£o
```bash
gcc -o main main.c
```

### Execu√ß√£o
```bash
./main
```

O programa ir√° processar automaticamente todos os arquivos na pasta `data/` e exibir:
- Lista de tokens encontrados
- Classifica√ß√£o de cada token
- Detec√ß√£o de erros l√©xicos
- Uso de mem√≥ria

## üìä Exemplo de Sa√≠da

```
==============================
Processando arquivo: ./data/Erro_Exemplo_9.txt

Total de tokens: 13

Classifica√ß√£o dos tokens:
tokens[0] = "principal" -> KEYWORD
tokens[1] = "(" -> LEFT_PAREN
tokens[2] = ")" -> RIGHT_PAREN
tokens[3] = "{" -> LEFT_BRACE
tokens[4] = "inteiro" -> KEYWORD
tokens[5] = "!a" -> VARIABLE
tokens[6] = "!b2" -> VARIABLE
tokens[7] = "=" -> IDENTIFIER/OTHER
tokens[8] = "7" -> INTEGER
tokens[9] = ";" -> SEMICOLON
tokens[10] = "escrva" -> LEXICAL ERROR

Mem√≥ria ocupada: 2048 Bytes ou 2.00 KB
```

## üîç Recursos T√©cnicos

### Gerenciamento de Mem√≥ria
- **Limite de mem√≥ria**: 2MB (2048 KB)
- **Aloca√ß√£o segura** com verifica√ß√£o de limites
- **Libera√ß√£o autom√°tica** de mem√≥ria

### Processamento de Arquivo
- **Leitura completa** do arquivo em mem√≥ria
- **Remo√ß√£o de BOM UTF-8** quando presente
- **Tokeniza√ß√£o** baseada em delimitadores

### Algoritmos Implementados
- **Dist√¢ncia de Levenshtein** para detec√ß√£o de similaridade
- **Tokeniza√ß√£o** com m√∫ltiplos delimitadores
- **Classifica√ß√£o autom√°tica** de tokens

## üë• Contribui√ß√£o

**Desenvolvido por:**
- [Davi Galdino](https://github.com/davi-ga)
- [Ana Misque](https://github.com/mxtqnt)

## üìÑ Licen√ßa

Este projeto foi desenvolvido para fins acad√™micos como parte do curso de Compiladores.

---
